## Определение токсичных комментариев

Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. 

Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.

Постройте модель со значением метрики качества *F1* не меньше 0.75. 

#### Используемые библиотеки
pandas numpy matplotlib scikit-learn lightgbm nltk pytorch re

## Общий вывод

По исходным данным (датасет из ~160 тыс. комментариев и отметки токсичности) необходимо разработать модель оценки токсичности комментария.  
Необходимо достичь показателя метрики F1-score не менее 0,75.

Для решения задачи данные загружены, очищены от не-латинских символов, приведены к нижнему регистру и лемматизированы.

Проведена проверка на дубликаты, которые были удалены из датасета.  
По итогу осталось почти 158 тыс. строк.

Данные разбиты на обучающую и тестовую выборки в оотношении 5:1; подготовлен пайплайн для обучения моделей с помощью tf-idf-векторизации.

Обучены модели классификации логистической регрессии, случайного леса LGBM.  
Оценка моделей проводилась по метрике F1-score.

С небольшим перевесом максимальный показатель метрики выдала модель логистической регрессии.

Лучшая модель проверена на тестовой выборке. Показатель целевой метрики составил 0,778, что удовлетворяет поставленной задаче.

---

Также проведен эксперимент с использованием нейронной сети BERT для поиска токсичных комментариев.  
Она показала заметно лучший результат (0,92).