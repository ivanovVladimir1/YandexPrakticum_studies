{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Краткий-вывод\" data-toc-modified-id=\"Краткий-вывод-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Краткий вывод</a></span></li><li><span><a href=\"#Подготовка-данных-к-обучению-моделей\" data-toc-modified-id=\"Подготовка-данных-к-обучению-моделей-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Подготовка данных к обучению моделей</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#LogisticRegression\" data-toc-modified-id=\"LogisticRegression-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>LogisticRegression</a></span></li><li><span><a href=\"#RandomForest\" data-toc-modified-id=\"RandomForest-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>RandomForest</a></span></li><li><span><a href=\"#LGBMClassifier\" data-toc-modified-id=\"LGBMClassifier-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>LGBMClassifier</a></span></li></ul></li><li><span><a href=\"#Краткий-вывод\" data-toc-modified-id=\"Краткий-вывод-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Краткий вывод</a></span><ul class=\"toc-item\"><li><span><a href=\"#Проверка-лучшей-модели-на-тестовой-выборке\" data-toc-modified-id=\"Проверка-лучшей-модели-на-тестовой-выборке-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Проверка лучшей модели на тестовой выборке</a></span></li><li><span><a href=\"#Краткий-вывод\" data-toc-modified-id=\"Краткий-вывод-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Краткий вывод</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import matplotlib.pyplot as plt\n",
    "from lightgbm import LGBMClassifier\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords as nltk_stopwords, wordnet\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from tqdm import notebook\n",
    "\n",
    "\n",
    "# Seed\n",
    "\n",
    "RS = 4613\n",
    "\n",
    "# Parameters\n",
    "\n",
    "pd.options.display.max_colwidth = 300\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember what page that's on?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                          text  \\\n",
       "0                                    Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27   \n",
       "1                                                                                                                                                                                             D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)   \n",
       "2                                                                    Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no...   \n",
       "4                                                                                                                                                                                                                                          You, sir, are my hero. Any chance you remember what page that's on?   \n",
       "\n",
       "   toxic  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pth1 = 'D:\\Temp\\Ya_Pr\\toxic_comments.csv'\n",
    "\n",
    "if os.path.exists(pth1):\n",
    "    data = pd.read_csv(pth1, index_col=[0])\n",
    "elif not os.path.exists(pth1):\n",
    "    data = pd.read_csv('https://code.s3.yandex.net//datasets//toxic_comments.csv', index_col=[0])\n",
    "else:\n",
    "    print('Something is wrong')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.pie(data['toxic'].value_counts(), labels=[0, 1], colors=['wheat', 'chocolate'], explode=[0.1, 0.1], shadow=True)\n",
    "\n",
    "plt.title('Распределение целевой переменной');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, явных дубликатов в данных нет.  \n",
    "Виден дисбаланс по целевой переменной (~9:1).\n",
    "\n",
    "Далее почистим текст "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\apple\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\apple\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\apple\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\apple\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(text):\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z ]', ' ', text )\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos(word):\n",
    "    \"\"\"\n",
    "    Map POS tag to first character lemmatize() accepts\n",
    "    \"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {'J': wordnet.ADJ,\n",
    "                'N': wordnet.NOUN,\n",
    "                'V': wordnet.VERB,\n",
    "                'R': wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystem2 = WordNetLemmatizer()\n",
    "\n",
    "def lemmer(texts):\n",
    "    text = cleaner(texts)\n",
    "    text = word_tokenize(text)\n",
    "    text = [word for word in text if word.lower() not in stops]\n",
    "\n",
    "    text = [mystem2.lemmatize(word, get_pos(word)) for word in text]\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159292/159292 [31:30<00:00, 84.25it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63374</th>\n",
       "      <td>Ah, you're correct - it was Political postions, not this article. My error. ?!?</td>\n",
       "      <td>0</td>\n",
       "      <td>ah correct political postions article error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2797</th>\n",
       "      <td>Language(s) \\n\\nPlease do not contribute text in Slovenian to English Wikipedia. Your contributions are more than welcome at the Slovenian Wikipedia.-</td>\n",
       "      <td>0</td>\n",
       "      <td>language please contribute text slovenian english wikipedia contribution welcome slovenian wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143594</th>\n",
       "      <td>\":I concur with the The Elements of Style and N5iln, the possessive should be \"\"Jobs's\"\"   \\n\\n\"</td>\n",
       "      <td>0</td>\n",
       "      <td>concur element style n iln possessive job</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56600</th>\n",
       "      <td>\"  while claiming, \"\"Rather than pick and choose ... which opinions ... we should insert in this article, we should not be inserting any\"\" \"</td>\n",
       "      <td>0</td>\n",
       "      <td>claim rather pick choose opinion insert article insert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79965</th>\n",
       "      <td>Removed self-reference on function \\n\\nJust wanted to drop you a quick courtesy note to let you know I reverted your addition of the (t)</td>\n",
       "      <td>0</td>\n",
       "      <td>remove self reference function want drop quick courtesy note let know revert addition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82098</th>\n",
       "      <td>I wonder if Wright's house is a tourist attraction like Johnny Adair's?</td>\n",
       "      <td>0</td>\n",
       "      <td>wonder wright house tourist attraction like johnny adair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88190</th>\n",
       "      <td>Blocks \\n\\nOh and by the way, she had already blocked me for no apparent reason right before I typed that out of anger. Why do you think I was so angry at her.</td>\n",
       "      <td>0</td>\n",
       "      <td>block oh way already block apparent reason right typed anger think angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48768</th>\n",
       "      <td>grow up \\n\\nGet a life</td>\n",
       "      <td>0</td>\n",
       "      <td>grow get life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133954</th>\n",
       "      <td>\"\\n\\nThis message is regarding the page User:Jpgordon. Please stop.  If you continue to vandalize pages, you will be blocked from editing Wikipedia.  «»?¿?meta \"</td>\n",
       "      <td>0</td>\n",
       "      <td>message regard page user jpgordon please stop continue vandalize page block edit wikipedia meta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15494</th>\n",
       "      <td>\"\\n\\n About .  \\n\\nI already e-mailed this report on . I hope that someone of serious Wikipedia administrators will read this report and take serious steps in protecting the Wikipedia dignity\\n\\nHello,\\n\\nI do understand that Wikipedia is a free encyclopaedia - but still some kind of very basic ...</td>\n",
       "      <td>0</td>\n",
       "      <td>already e mail report hope someone serious wikipedia administrator read report take serious step protect wikipedia dignity hello understand wikipedia free encyclopaedia still kind basic ethicalrules shall applicable oblige editor notice person whose nick name http en wikipedia org wiki user spyl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                               text  \\\n",
       "63374                                                                                                                                                                                                                               Ah, you're correct - it was Political postions, not this article. My error. ?!?   \n",
       "2797                                                                                                                                                         Language(s) \\n\\nPlease do not contribute text in Slovenian to English Wikipedia. Your contributions are more than welcome at the Slovenian Wikipedia.-   \n",
       "143594                                                                                                                                                                                                             \":I concur with the The Elements of Style and N5iln, the possessive should be \"\"Jobs's\"\"   \\n\\n\"   \n",
       "56600                                                                                                                                                                  \"  while claiming, \"\"Rather than pick and choose ... which opinions ... we should insert in this article, we should not be inserting any\"\" \"   \n",
       "79965                                                                                                                                                                      Removed self-reference on function \\n\\nJust wanted to drop you a quick courtesy note to let you know I reverted your addition of the (t)   \n",
       "82098                                                                                                                                                                                                                                       I wonder if Wright's house is a tourist attraction like Johnny Adair's?   \n",
       "88190                                                                                                                                               Blocks \\n\\nOh and by the way, she had already blocked me for no apparent reason right before I typed that out of anger. Why do you think I was so angry at her.   \n",
       "48768                                                                                                                                                                                                                                                                                        grow up \\n\\nGet a life   \n",
       "133954                                                                                                                                            \"\\n\\nThis message is regarding the page User:Jpgordon. Please stop.  If you continue to vandalize pages, you will be blocked from editing Wikipedia.  «»?¿?meta \"   \n",
       "15494   \"\\n\\n About .  \\n\\nI already e-mailed this report on . I hope that someone of serious Wikipedia administrators will read this report and take serious steps in protecting the Wikipedia dignity\\n\\nHello,\\n\\nI do understand that Wikipedia is a free encyclopaedia - but still some kind of very basic ...   \n",
       "\n",
       "        toxic  \\\n",
       "63374       0   \n",
       "2797        0   \n",
       "143594      0   \n",
       "56600       0   \n",
       "79965       0   \n",
       "82098       0   \n",
       "88190       0   \n",
       "48768       0   \n",
       "133954      0   \n",
       "15494       0   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                          lemm_text  \n",
       "63374                                                                                                                                                                                                                                                                   ah correct political postions article error  \n",
       "2797                                                                                                                                                                                                           language please contribute text slovenian english wikipedia contribution welcome slovenian wikipedia  \n",
       "143594                                                                                                                                                                                                                                                                    concur element style n iln possessive job  \n",
       "56600                                                                                                                                                                                                                                                        claim rather pick choose opinion insert article insert  \n",
       "79965                                                                                                                                                                                                                         remove self reference function want drop quick courtesy note let know revert addition  \n",
       "82098                                                                                                                                                                                                                                                      wonder wright house tourist attraction like johnny adair  \n",
       "88190                                                                                                                                                                                                                                      block oh way already block apparent reason right typed anger think angry  \n",
       "48768                                                                                                                                                                                                                                                                                                 grow get life  \n",
       "133954                                                                                                                                                                                                              message regard page user jpgordon please stop continue vandalize page block edit wikipedia meta  \n",
       "15494   already e mail report hope someone serious wikipedia administrator read report take serious step protect wikipedia dignity hello understand wikipedia free encyclopaedia still kind basic ethicalrules shall applicable oblige editor notice person whose nick name http en wikipedia org wiki user spyl...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stops = set(nltk_stopwords.words('english'))\n",
    "\n",
    "\n",
    "tqdm.pandas()\n",
    "data['lemm_text'] = data['text'].progress_apply(lemmer)\n",
    "data.sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text = str([''.join(string) for string in data['lemm_text']])\n",
    "\n",
    "text_tokens = word_tokenize(cleaner(text))\n",
    "\n",
    "fdist = FreqDist(text_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = fdist.most_common(15)\n",
    "\n",
    "word_for_plot = {}\n",
    "\n",
    "for i in top_words:\n",
    "    word_for_plot[i[0]] = i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.title('Частотность слов')\n",
    "plt.xlabel('Наиболее часто встречаемые слова')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Количество')\n",
    "\n",
    "plt.bar(word_for_plot.keys(), word_for_plot.values())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "text = str([''.join(string) for string in data[data['toxic'] == 1]['lemm_text']])\n",
    "\n",
    "text_tokens = word_tokenize(cleaner(text))\n",
    "\n",
    "fdist = FreqDist(text_tokens)\n",
    "\n",
    "top_words = fdist.most_common(15)\n",
    "\n",
    "word_for_plot = {}\n",
    "\n",
    "for i in top_words:\n",
    "    word_for_plot[i[0]] = i[1]\n",
    "\n",
    "\n",
    "plt.title('Частотность слов')\n",
    "plt.xlabel('Наиболее часто встречаемые токсичные слова')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Количество')\n",
    "\n",
    "plt.bar(word_for_plot.keys(), word_for_plot.values())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "text = str([''.join(string) for string in data[data['toxic'] == 0]['lemm_text']])\n",
    "\n",
    "text_tokens = word_tokenize(cleaner(text))\n",
    "\n",
    "fdist = FreqDist(text_tokens)\n",
    "\n",
    "top_words = fdist.most_common(15)\n",
    "\n",
    "word_for_plot = {}\n",
    "\n",
    "for i in top_words:\n",
    "    word_for_plot[i[0]] = i[1]\n",
    "\n",
    "\n",
    "plt.title('Частотность слов')\n",
    "plt.xlabel('Наиболее часто встречаемые нетоксичные слова')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Количество')\n",
    "\n",
    "plt.bar(word_for_plot.keys(), word_for_plot.values())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно из графиков, в токсичных твитах чаще встречаются оскорбительные слова.\n",
    "\n",
    "Интересно, что \"wikipedia\" примерно одинаково часто встречается и в токсичных, и в нетоксичных твитах.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2091</th>\n",
       "      <td>No, it doesn´t.80.228.65.162</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2400</th>\n",
       "      <td>Here, here and here.</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3983</th>\n",
       "      <td>From here\\n\\nFrom here 160.80.2.8</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4475</th>\n",
       "      <td>1993\\n\\n1994\\n\\n1995\\n\\n1996\\n\\n1997\\n\\n1998\\n\\n1999\\n\\n2000\\n\\n2001\\n\\n2002\\n\\n2003</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6293</th>\n",
       "      <td>193.61.111.53  15:00</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148751</th>\n",
       "      <td>she did 76.122.79.82</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151263</th>\n",
       "      <td>10 - 2010 04 08 to 2010 05 12</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152700</th>\n",
       "      <td>SAME FOR THIS 166.137.240.20</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153198</th>\n",
       "      <td>which is OVER 9000 OVER 9000 OVER 9000 OVER 9000 OVER 9000 OVER 9000 OVER 9000 OVER 9000 OVER 9000 OVER 9000 OVER 9000 OVER 9000 OVER 9000 OVER 9000 OVER 9000 OVER 9000 OVER 9000 OVER 9000 OVER 9000 OVER 9000 OVER 9000 OVER 9000 OVER 9000 OVER 9000 OVER 9000 OVER 9000 OVER 9000 OVER 9000 OVER 90...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158899</th>\n",
       "      <td>Why don't you do it? 24.68.148.215</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                               text  \\\n",
       "2091                                                                                                                                                                                                                                                                                   No, it doesn´t.80.228.65.162   \n",
       "2400                                                                                                                                                                                                                                                                                           Here, here and here.   \n",
       "3983                                                                                                                                                                                                                                                                              From here\\n\\nFrom here 160.80.2.8   \n",
       "4475                                                                                                                                                                                                                           1993\\n\\n1994\\n\\n1995\\n\\n1996\\n\\n1997\\n\\n1998\\n\\n1999\\n\\n2000\\n\\n2001\\n\\n2002\\n\\n2003   \n",
       "6293                                                                                                                                                                                                                                                                                           193.61.111.53  15:00   \n",
       "...                                                                                                                                                                                                                                                                                                             ...   \n",
       "148751                                                                                                                                                                                                                                                                                         she did 76.122.79.82   \n",
       "151263                                                                                                                                                                                                                                                                                10 - 2010 04 08 to 2010 05 12   \n",
       "152700                                                                                                                                                                                                                                                                                 SAME FOR THIS 166.137.240.20   \n",
       "153198  which is OVER 9000 OVER 9000 OVER 9000 OVER 9000 OVER 9000 OVER 9000 OVER 9000 OVER 9000 OVER 9000 OVER 9000 OVER 9000 OVER 9000 OVER 9000 OVER 9000 OVER 9000 OVER 9000 OVER 9000 OVER 9000 OVER 9000 OVER 9000 OVER 9000 OVER 9000 OVER 9000 OVER 9000 OVER 9000 OVER 9000 OVER 9000 OVER 9000 OVER 90...   \n",
       "158899                                                                                                                                                                                                                                                                           Why don't you do it? 24.68.148.215   \n",
       "\n",
       "        toxic lemm_text  \n",
       "2091        0            \n",
       "2400        0            \n",
       "3983        0            \n",
       "4475        0            \n",
       "6293        0            \n",
       "...       ...       ...  \n",
       "148751      0            \n",
       "151263      0            \n",
       "152700      0            \n",
       "153198      0            \n",
       "158899      0            \n",
       "\n",
       "[62 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['lemm_text'] == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.983871\n",
       "1    0.016129\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['lemm_text'] == '']['toxic'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "from PIL import Image, ImageDraw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = str([''.join(string) for string in data['lemm_text']])\n",
    "\n",
    "text_tokens = word_tokenize(cleaner(text))\n",
    "\n",
    "text_raw = \" \".join(text_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем облако тегов для датасета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_mask = np.array(Image.open('./tweet.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wordcloud = WordCloud(\n",
    "    background_color='white',\n",
    "    mask = meta_mask, \n",
    "    contour_width = 7,\n",
    "    contour_color = 'blue'\n",
    ").generate(text_raw)\n",
    "\n",
    "im = Image.new(\"RGB\", (0, 0))\n",
    "draw = ImageDraw.Draw(im)\n",
    "box_size = draw.textbbox((0, 0), text_raw)\n",
    "\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим на дубликаты после обработки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1898"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['lemm_text', 'toxic']].duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После обработки и лемматизации появились дубликаты.  \n",
    "Уберем их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(157394, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop_duplicates(subset=['lemm_text', 'toxic'], inplace=True)\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поищем короткие и длинные комментарии.  \n",
    "Для этого введем столбец с количеством слов в твите."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['len'] = data['lemm_text'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_text</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2091</th>\n",
       "      <td>No, it doesn´t.80.228.65.162</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119123</th>\n",
       "      <td>\"\"\"</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109472</th>\n",
       "      <td>No, you have to prove that I can't.</td>\n",
       "      <td>0</td>\n",
       "      <td>prove</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19150</th>\n",
       "      <td>You are more than welcome to do it yourself.</td>\n",
       "      <td>0</td>\n",
       "      <td>welcome</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50630</th>\n",
       "      <td>Testing. 220.255.2.139</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29133</th>\n",
       "      <td>, and I'm not biting.</td>\n",
       "      <td>0</td>\n",
       "      <td>biting</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57311</th>\n",
       "      <td>Your point being? 86.173.139.210</td>\n",
       "      <td>0</td>\n",
       "      <td>point</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112907</th>\n",
       "      <td>o no all these bastardsllpaybad</td>\n",
       "      <td>1</td>\n",
       "      <td>bastardsllpaybad</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117893</th>\n",
       "      <td>Just disregard this all.</td>\n",
       "      <td>0</td>\n",
       "      <td>disregard</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78613</th>\n",
       "      <td>I will look into what to do about this.</td>\n",
       "      <td>0</td>\n",
       "      <td>look</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57259</th>\n",
       "      <td>It is there darn it</td>\n",
       "      <td>0</td>\n",
       "      <td>darn</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8122</th>\n",
       "      <td>Achtung y'all...</td>\n",
       "      <td>0</td>\n",
       "      <td>achtung</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64396</th>\n",
       "      <td>Just a misunderstanding.</td>\n",
       "      <td>0</td>\n",
       "      <td>misunderstand</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2567</th>\n",
       "      <td>which has now been removed</td>\n",
       "      <td>0</td>\n",
       "      <td>remove</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29459</th>\n",
       "      <td>I had little to do with the ;</td>\n",
       "      <td>0</td>\n",
       "      <td>little</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126673</th>\n",
       "      <td>]] other than by [[AFDW</td>\n",
       "      <td>0</td>\n",
       "      <td>afdw</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138223</th>\n",
       "      <td>But what if you *are* a fascist?</td>\n",
       "      <td>1</td>\n",
       "      <td>fascist</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82149</th>\n",
       "      <td>I'm not familiar with it.</td>\n",
       "      <td>0</td>\n",
       "      <td>familiar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125702</th>\n",
       "      <td>Friend of yours? \\n\\n∇∆∇∆</td>\n",
       "      <td>0</td>\n",
       "      <td>friend</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29515</th>\n",
       "      <td>And so it begins again...</td>\n",
       "      <td>0</td>\n",
       "      <td>begin</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>I've just seen that</td>\n",
       "      <td>0</td>\n",
       "      <td>see</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112984</th>\n",
       "      <td>What was unsourced?</td>\n",
       "      <td>0</td>\n",
       "      <td>unsourced</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7835</th>\n",
       "      <td>But they are not the same person!</td>\n",
       "      <td>0</td>\n",
       "      <td>person</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2622</th>\n",
       "      <td>\"::Thanks.   (Μελ Ετητης) \\n\\n\"</td>\n",
       "      <td>0</td>\n",
       "      <td>thanks</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99045</th>\n",
       "      <td>Ok, I will do it.200.216.63.82</td>\n",
       "      <td>0</td>\n",
       "      <td>ok</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19644</th>\n",
       "      <td>I did it!  Hooray for me.</td>\n",
       "      <td>0</td>\n",
       "      <td>hooray</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145389</th>\n",
       "      <td>(or candidacy for same)</td>\n",
       "      <td>0</td>\n",
       "      <td>candidacy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72453</th>\n",
       "      <td>Also, 128.61.126.234</td>\n",
       "      <td>0</td>\n",
       "      <td>also</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28678</th>\n",
       "      <td>My pleasureyou too,</td>\n",
       "      <td>0</td>\n",
       "      <td>pleasureyou</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88807</th>\n",
       "      <td>I'll attack you! 32.210.212.23</td>\n",
       "      <td>1</td>\n",
       "      <td>attack</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic         lemm_text  \\\n",
       "2091                    No, it doesn´t.80.228.65.162      0                     \n",
       "119123                                           \"\"\"      1                     \n",
       "109472           No, you have to prove that I can't.      0             prove   \n",
       "19150   You are more than welcome to do it yourself.      0           welcome   \n",
       "50630                         Testing. 220.255.2.139      0              test   \n",
       "29133                          , and I'm not biting.      0            biting   \n",
       "57311               Your point being? 86.173.139.210      0             point   \n",
       "112907               o no all these bastardsllpaybad      1  bastardsllpaybad   \n",
       "117893                      Just disregard this all.      0         disregard   \n",
       "78613        I will look into what to do about this.      0              look   \n",
       "57259                            It is there darn it      0              darn   \n",
       "8122                                Achtung y'all...      0           achtung   \n",
       "64396                       Just a misunderstanding.      0     misunderstand   \n",
       "2567                      which has now been removed      0            remove   \n",
       "29459                  I had little to do with the ;      0            little   \n",
       "126673                       ]] other than by [[AFDW      0              afdw   \n",
       "138223              But what if you *are* a fascist?      1           fascist   \n",
       "82149                      I'm not familiar with it.      0          familiar   \n",
       "125702                     Friend of yours? \\n\\n∇∆∇∆      0            friend   \n",
       "29515                      And so it begins again...      0             begin   \n",
       "899                              I've just seen that      0               see   \n",
       "112984                           What was unsourced?      0         unsourced   \n",
       "7835               But they are not the same person!      0            person   \n",
       "2622                 \"::Thanks.   (Μελ Ετητης) \\n\\n\"      0            thanks   \n",
       "99045                 Ok, I will do it.200.216.63.82      0                ok   \n",
       "19644                      I did it!  Hooray for me.      0            hooray   \n",
       "145389                       (or candidacy for same)      0         candidacy   \n",
       "72453                           Also, 128.61.126.234      0              also   \n",
       "28678                            My pleasureyou too,      0       pleasureyou   \n",
       "88807                 I'll attack you! 32.210.212.23      1            attack   \n",
       "\n",
       "        len  \n",
       "2091      0  \n",
       "119123    0  \n",
       "109472    1  \n",
       "19150     1  \n",
       "50630     1  \n",
       "29133     1  \n",
       "57311     1  \n",
       "112907    1  \n",
       "117893    1  \n",
       "78613     1  \n",
       "57259     1  \n",
       "8122      1  \n",
       "64396     1  \n",
       "2567      1  \n",
       "29459     1  \n",
       "126673    1  \n",
       "138223    1  \n",
       "82149     1  \n",
       "125702    1  \n",
       "29515     1  \n",
       "899       1  \n",
       "112984    1  \n",
       "7835      1  \n",
       "2622      1  \n",
       "99045     1  \n",
       "19644     1  \n",
       "145389    1  \n",
       "72453     1  \n",
       "28678     1  \n",
       "88807     1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sort_values(by='len').head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Строк с длиной 1 или 0 слов: 2\n"
     ]
    }
   ],
   "source": [
    "print('Строк с длиной 1 или 0 слов:', data.query('len <= 0').shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "58 строк, лемматизированных в одно слово. Думаю, можно безболезненно удалить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(157392, 4)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.query('len > 0')\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим с другого конца датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_text</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32114</th>\n",
       "      <td>PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG ...</td>\n",
       "      <td>1</td>\n",
       "      <td>pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig ...</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76542</th>\n",
       "      <td>DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG ...</td>\n",
       "      <td>1</td>\n",
       "      <td>die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag ...</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149925</th>\n",
       "      <td>LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL ...</td>\n",
       "      <td>0</td>\n",
       "      <td>lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol ...</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61746</th>\n",
       "      <td>OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES ...</td>\n",
       "      <td>0</td>\n",
       "      <td>oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh...</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153236</th>\n",
       "      <td>FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW ...</td>\n",
       "      <td>1</td>\n",
       "      <td>fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew ...</td>\n",
       "      <td>1247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32371</th>\n",
       "      <td>THAT WAS REALLY MILLESECONDS WASNT IT BITCH \\n\\nFAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW ...</td>\n",
       "      <td>1</td>\n",
       "      <td>really milleseconds wasnt bitch fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew ...</td>\n",
       "      <td>1235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106871</th>\n",
       "      <td>hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron...</td>\n",
       "      <td>1</td>\n",
       "      <td>hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron...</td>\n",
       "      <td>1078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6564</th>\n",
       "      <td>Sex sex sex sex Sex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex se...</td>\n",
       "      <td>1</td>\n",
       "      <td>sex sex sex sex sex sex sex sexsex sex sex sexsex sex sex sexsex sex sex sexsex sex sex sexsex sex sex sexsex sex sex sexsex sex sex sexsex sex sex sexsex sex sex sexsex sex sex sexsex sex sex sexsex sex sex sexsex sex sex sexsex sex sex sexsex sex sex sexsex sex sex sexsex sex sex sexsex sex se...</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101685</th>\n",
       "      <td>SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER ...</td>\n",
       "      <td>1</td>\n",
       "      <td>super gay super gay super gay super gay super gay super gay super gay super gay super gay super gay super gay super gay super gay super gay super gay super gay super gay super gay super gay super gay super gay super gay super gay super gay super gay super gay super gay super gay super gay super ...</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38030</th>\n",
       "      <td>Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark B...</td>\n",
       "      <td>1</td>\n",
       "      <td>bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark b...</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87388</th>\n",
       "      <td>SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT S...</td>\n",
       "      <td>1</td>\n",
       "      <td>shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit s...</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13041</th>\n",
       "      <td>fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitc...</td>\n",
       "      <td>1</td>\n",
       "      <td>fuck u bitch fuck u bitch fuck u bitch fuck u bitch fuck u bitch fuck u bitch fuck u bitch fuck u bitch fuck u bitch fuck u bitch fuck u bitch fuck u bitch fuck u bitch fuck u bitch fuck u bitch fuck u bitch fuck u bitch fuck u bitch fuck u bitch fuck u bitch fuck u bitch fuck u bitch fuck u bit...</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11946</th>\n",
       "      <td>fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish f...</td>\n",
       "      <td>0</td>\n",
       "      <td>fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish f...</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27124</th>\n",
       "      <td>DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU...</td>\n",
       "      <td>1</td>\n",
       "      <td>damn u cunt damn u cunt damn u cunt damn u cunt damn u cunt damn u cunt damn u cunt damn u cunt damn u cunt damn u cunt damn u cunt damn u cunt damn u cunt damn u cunt damn u cunt damn u cunt damn u cunt damn u cunt damn u cunt damn u cunt damn u cunt damn u cunt damn u cunt damn u cunt damn u c...</td>\n",
       "      <td>937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69794</th>\n",
       "      <td>hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i li...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey like jew hey like jew hey like jew hey like jew hey like jew hey like jew hey like jew hey like jew hey like jew hey like jew hey like jew hey like jew hey like jew hey like jew hey like jew hey like jew hey like jew hey like jew hey like jew hey like jew hey like jew hey like jew hey like j...</td>\n",
       "      <td>935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55111</th>\n",
       "      <td>ANYONE WHO SUPPORTS THIS IS FUCKING SICK. MEN AND UNDERAGED FUCKING KIDS?????????????????????????????? WHAT IN THE FUCK YOU ALL SHOULD BE SHOT AND KILLED YOU BUNCH OF FUCKING FAGGOT PEDOPHILES\\n\\nDIE DIE DIE DIE DI EDIE DIE DIE DIE DIE\\n\\nDIE DIE DIE DIE DI EDIE DIE DIE DIE DIE\\n\\nDIE DIE DIE DI...</td>\n",
       "      <td>1</td>\n",
       "      <td>anyone support fuck sick men underaged fuck kid fuck shot kill bunch fuck faggot pedophile die die die die di edie die die die die die die die die di edie die die die die die die die die di edie die die die die die die die die di edie die die die die die die die die di edie die die die die die d...</td>\n",
       "      <td>915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93879</th>\n",
       "      <td>wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS...</td>\n",
       "      <td>1</td>\n",
       "      <td>wiki noobs wiki noobs wiki noobs wiki noobs wiki noobs wiki noobs wiki noobs wiki noobs wiki noobs wiki noobs wiki noobs wiki noobs wiki noobs wiki noobs wiki noobs wiki noobs wiki noobs wiki noobs wiki noobs wiki noobs wiki noobs wiki noobs wiki noobs wiki noobs wiki noobs wiki noobs wiki noobs...</td>\n",
       "      <td>910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155912</th>\n",
       "      <td>AIDS AIDS AIDS AIDS AIDS AIDS AIDSAIDS AIDS AIDS AIDS AIDS AIDS AIDSAIDS AIDS AIDS AIDS AIDS AIDS AIDSAIDS AIDS AIDS AIDS AIDS AIDS AIDSAIDS AIDS AIDS AIDS AIDS AIDS AIDSAIDS AIDS AIDS AIDS AIDS AIDS AIDSAIDS AIDS AIDS AIDS AIDS AIDS AIDSAIDS AIDS AIDS AIDS AIDS AIDS AIDSAIDS AIDS AIDS AIDS AIDS...</td>\n",
       "      <td>1</td>\n",
       "      <td>aid aid aid aid aid aid aidsaids aid aid aid aid aid aidsaids aid aid aid aid aid aidsaids aid aid aid aid aid aidsaids aid aid aid aid aid aidsaids aid aid aid aid aid aidsaids aid aid aid aid aid aidsaids aid aid aid aid aid aidsaids aid aid aid aid aid aidsaids aid aid aid aid aid aidsaids ai...</td>\n",
       "      <td>883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72136</th>\n",
       "      <td>China smells like fart. China smells like fart.China smells like fart.China smells like fart.China smells like fart.China smells like fart.China smells like fart.China smells like fart.China smells like fart.China smells like fart.China smells like fart.China smells like fart.China smells like f...</td>\n",
       "      <td>1</td>\n",
       "      <td>china smell like fart china smell like fart china smell like fart china smell like fart china smell like fart china smell like fart china smell like fart china smell like fart china smell like fart china smell like fart china smell like fart china smell like fart china smell like fart china smel...</td>\n",
       "      <td>870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2413</th>\n",
       "      <td>FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS B...</td>\n",
       "      <td>1</td>\n",
       "      <td>fuck u useless bot fuck u useless bot fuck u useless bot fuck u useless bot fuck u useless bot fuck u useless bot fuck u useless bot fuck u useless bot fuck u useless bot fuck u useless bot fuck u useless bot fuck u useless bot fuck u useless bot fuck u useless bot fuck u useless bot fuck u usel...</td>\n",
       "      <td>869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8697</th>\n",
       "      <td>BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BA...</td>\n",
       "      <td>1</td>\n",
       "      <td>ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball b...</td>\n",
       "      <td>834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47667</th>\n",
       "      <td>Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Bl...</td>\n",
       "      <td>0</td>\n",
       "      <td>block block block block block block block block block block block block block block block block block block block block block block block block block block block block block block block block block block block block block block block block block block block block block block block block block bl...</td>\n",
       "      <td>834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18168</th>\n",
       "      <td>Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken ri...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey guy love chicken rice hey guy love chicken rice hey guy love chicken rice hey guy love chicken rice hey guy love chicken rice hey guy love chicken rice hey guy love chicken rice hey guy love chicken rice hey guy love chicken rice hey guy love chicken rice hey guy love chicken rice hey guy lo...</td>\n",
       "      <td>834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156317</th>\n",
       "      <td>HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAG...</td>\n",
       "      <td>1</td>\n",
       "      <td>huge faggot huge faggot huge faggot huge faggot huge faggot huge faggot huge faggot huge faggot huge faggot huge faggot huge faggot huge faggot huge faggot huge faggot huge faggot huge faggot huge faggot huge faggot huge faggot huge faggot huge faggot huge faggot huge faggot huge faggot huge fag...</td>\n",
       "      <td>834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153790</th>\n",
       "      <td>btw mark arsten is a son of a bitch his cock is placed in a girls mouth \\nHey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I l...</td>\n",
       "      <td>1</td>\n",
       "      <td>btw mark arsten son bitch cock place girl mouth hey guy love chicken rice hey guy love chicken rice hey guy love chicken rice hey guy love chicken rice hey guy love chicken rice hey guy love chicken rice hey guy love chicken rice hey guy love chicken rice hey guy love chicken rice hey guy love c...</td>\n",
       "      <td>829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104904</th>\n",
       "      <td>mamas boy mamas boy mamas boy mamas boymamas boy mamas boymamas boy mamas boymamas boy mamas boymamas boy mamas boymamas boy mamas boymamas boy mamas boymamas boy mamas boymamas boy mamas boymamas boy mamas boymamas boy mamas boymamas boy mamas boymamas boy mamas boymamas boy mamas boymamas boy ...</td>\n",
       "      <td>0</td>\n",
       "      <td>mama boy mama boy mama boy mama boymamas boy mama boymamas boy mama boymamas boy mama boymamas boy mama boymamas boy mama boymamas boy mama boymamas boy mama boymamas boy mama boymamas boy mama boymamas boy mama boymamas boy mama boymamas boy mama boymamas boy mama boymamas boy mama boymamas boy...</td>\n",
       "      <td>793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76128</th>\n",
       "      <td>nice work removing edits, faggot ass piece of shit nice work removing edits, faggot ass piece of shit nice work removing edits, faggot ass piece of shit nice work removing edits, faggot ass piece of shit nice work removing edits, faggot ass piece of shit nice work removing edits, faggot ass piec...</td>\n",
       "      <td>1</td>\n",
       "      <td>nice work remove edits faggot as piece shit nice work remove edits faggot as piece shit nice work remove edits faggot as piece shit nice work remove edits faggot as piece shit nice work remove edits faggot as piece shit nice work remove edits faggot as piece shit nice work remove edits faggot as...</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46150</th>\n",
       "      <td>heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitle...</td>\n",
       "      <td>1</td>\n",
       "      <td>heil hitler heil hitler heil hitler heil hitler heil hitler heil hitler heil hitler heil hitler heil hitler heil hitler heil hitler heil hitler heil hitler heil hitler heil hitler heil hitler heil hitler heil hitler heil hitler heil hitler heil hitler heil hitler heil hitler heil hitler heil hit...</td>\n",
       "      <td>770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131633</th>\n",
       "      <td>\"FFFFF UUUUUU CCCCCC KKKKKK ===== YOU! F UU C KK YOU FFFFF UUUUUU CCCCCC KKKKKK ===== YOU! F UU C KK YOU FFFFF UUUUUU CCCCCC KKKKKK ===== YOU! F UU C KK YOU FFFFF UUUUUU CCCCCC KKKKKK ===== YOU! F UU C KK YOU FFFFF UUUUUU CCCCCC KKKKKK ===== YOU! F UU C KK YOU FFFFF UUUUUU CCCCCC KKKKKK ===== YO...</td>\n",
       "      <td>1</td>\n",
       "      <td>fffff uuuuuu cccccc kkkkkk f uu c kk fffff uuuuuu cccccc kkkkkk f uu c kk fffff uuuuuu cccccc kkkkkk f uu c kk fffff uuuuuu cccccc kkkkkk f uu c kk fffff uuuuuu cccccc kkkkkk f uu c kk fffff uuuuuu cccccc kkkkkk f uu c kk fffff uuuuuu cccccc kkkkkk f uu c kk fffff uuuuuu cccccc kkkkkk f uu c kk ...</td>\n",
       "      <td>770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17319</th>\n",
       "      <td>hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi \\n\\nhi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron h...</td>\n",
       "      <td>1</td>\n",
       "      <td>hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi mo...</td>\n",
       "      <td>765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                               text  \\\n",
       "32114   PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG ...   \n",
       "76542   DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG ...   \n",
       "149925  LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL ...   \n",
       "61746   OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES ...   \n",
       "153236  FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW ...   \n",
       "32371   THAT WAS REALLY MILLESECONDS WASNT IT BITCH \\n\\nFAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW ...   \n",
       "106871  hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron...   \n",
       "6564    Sex sex sex sex Sex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex se...   \n",
       "101685  SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER ...   \n",
       "38030   Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark B...   \n",
       "87388   SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT S...   \n",
       "13041   fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitc...   \n",
       "11946   fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish f...   \n",
       "27124   DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU...   \n",
       "69794   hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i li...   \n",
       "55111   ANYONE WHO SUPPORTS THIS IS FUCKING SICK. MEN AND UNDERAGED FUCKING KIDS?????????????????????????????? WHAT IN THE FUCK YOU ALL SHOULD BE SHOT AND KILLED YOU BUNCH OF FUCKING FAGGOT PEDOPHILES\\n\\nDIE DIE DIE DIE DI EDIE DIE DIE DIE DIE\\n\\nDIE DIE DIE DIE DI EDIE DIE DIE DIE DIE\\n\\nDIE DIE DIE DI...   \n",
       "93879   wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS...   \n",
       "155912  AIDS AIDS AIDS AIDS AIDS AIDS AIDSAIDS AIDS AIDS AIDS AIDS AIDS AIDSAIDS AIDS AIDS AIDS AIDS AIDS AIDSAIDS AIDS AIDS AIDS AIDS AIDS AIDSAIDS AIDS AIDS AIDS AIDS AIDS AIDSAIDS AIDS AIDS AIDS AIDS AIDS AIDSAIDS AIDS AIDS AIDS AIDS AIDS AIDSAIDS AIDS AIDS AIDS AIDS AIDS AIDSAIDS AIDS AIDS AIDS AIDS...   \n",
       "72136   China smells like fart. China smells like fart.China smells like fart.China smells like fart.China smells like fart.China smells like fart.China smells like fart.China smells like fart.China smells like fart.China smells like fart.China smells like fart.China smells like fart.China smells like f...   \n",
       "2413    FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS B...   \n",
       "8697    BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BA...   \n",
       "47667   Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Bl...   \n",
       "18168   Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken ri...   \n",
       "156317  HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAG...   \n",
       "153790  btw mark arsten is a son of a bitch his cock is placed in a girls mouth \\nHey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I l...   \n",
       "104904  mamas boy mamas boy mamas boy mamas boymamas boy mamas boymamas boy mamas boymamas boy mamas boymamas boy mamas boymamas boy mamas boymamas boy mamas boymamas boy mamas boymamas boy mamas boymamas boy mamas boymamas boy mamas boymamas boy mamas boymamas boy mamas boymamas boy mamas boymamas boy ...   \n",
       "76128   nice work removing edits, faggot ass piece of shit nice work removing edits, faggot ass piece of shit nice work removing edits, faggot ass piece of shit nice work removing edits, faggot ass piece of shit nice work removing edits, faggot ass piece of shit nice work removing edits, faggot ass piec...   \n",
       "46150   heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitle...   \n",
       "131633  \"FFFFF UUUUUU CCCCCC KKKKKK ===== YOU! F UU C KK YOU FFFFF UUUUUU CCCCCC KKKKKK ===== YOU! F UU C KK YOU FFFFF UUUUUU CCCCCC KKKKKK ===== YOU! F UU C KK YOU FFFFF UUUUUU CCCCCC KKKKKK ===== YOU! F UU C KK YOU FFFFF UUUUUU CCCCCC KKKKKK ===== YOU! F UU C KK YOU FFFFF UUUUUU CCCCCC KKKKKK ===== YO...   \n",
       "17319   hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi \\n\\nhi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron h...   \n",
       "\n",
       "        toxic  \\\n",
       "32114       1   \n",
       "76542       1   \n",
       "149925      0   \n",
       "61746       0   \n",
       "153236      1   \n",
       "32371       1   \n",
       "106871      1   \n",
       "6564        1   \n",
       "101685      1   \n",
       "38030       1   \n",
       "87388       1   \n",
       "13041       1   \n",
       "11946       0   \n",
       "27124       1   \n",
       "69794       0   \n",
       "55111       1   \n",
       "93879       1   \n",
       "155912      1   \n",
       "72136       1   \n",
       "2413        1   \n",
       "8697        1   \n",
       "47667       0   \n",
       "18168       0   \n",
       "156317      1   \n",
       "153790      1   \n",
       "104904      0   \n",
       "76128       1   \n",
       "46150       1   \n",
       "131633      1   \n",
       "17319       1   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                          lemm_text  \\\n",
       "32114   pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig ...   \n",
       "76542   die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag die fag ...   \n",
       "149925  lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol lol ...   \n",
       "61746   oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh no oh...   \n",
       "153236  fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew ...   \n",
       "32371   really milleseconds wasnt bitch fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew fat jew ...   \n",
       "106871  hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron...   \n",
       "6564    sex sex sex sex sex sex sex sexsex sex sex sexsex sex sex sexsex sex sex sexsex sex sex sexsex sex sex sexsex sex sex sexsex sex sex sexsex sex sex sexsex sex sex sexsex sex sex sexsex sex sex sexsex sex sex sexsex sex sex sexsex sex sex sexsex sex sex sexsex sex sex sexsex sex sex sexsex sex se...   \n",
       "101685  super gay super gay super gay super gay super gay super gay super gay super gay super gay super gay super gay super gay super gay super gay super gay super gay super gay super gay super gay super gay super gay super gay super gay super gay super gay super gay super gay super gay super gay super ...   \n",
       "38030   bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark bark b...   \n",
       "87388   shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit shit s...   \n",
       "13041   fuck u bitch fuck u bitch fuck u bitch fuck u bitch fuck u bitch fuck u bitch fuck u bitch fuck u bitch fuck u bitch fuck u bitch fuck u bitch fuck u bitch fuck u bitch fuck u bitch fuck u bitch fuck u bitch fuck u bitch fuck u bitch fuck u bitch fuck u bitch fuck u bitch fuck u bitch fuck u bit...   \n",
       "11946   fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish f...   \n",
       "27124   damn u cunt damn u cunt damn u cunt damn u cunt damn u cunt damn u cunt damn u cunt damn u cunt damn u cunt damn u cunt damn u cunt damn u cunt damn u cunt damn u cunt damn u cunt damn u cunt damn u cunt damn u cunt damn u cunt damn u cunt damn u cunt damn u cunt damn u cunt damn u cunt damn u c...   \n",
       "69794   hey like jew hey like jew hey like jew hey like jew hey like jew hey like jew hey like jew hey like jew hey like jew hey like jew hey like jew hey like jew hey like jew hey like jew hey like jew hey like jew hey like jew hey like jew hey like jew hey like jew hey like jew hey like jew hey like j...   \n",
       "55111   anyone support fuck sick men underaged fuck kid fuck shot kill bunch fuck faggot pedophile die die die die di edie die die die die die die die die di edie die die die die die die die die di edie die die die die die die die die di edie die die die die die die die die di edie die die die die die d...   \n",
       "93879   wiki noobs wiki noobs wiki noobs wiki noobs wiki noobs wiki noobs wiki noobs wiki noobs wiki noobs wiki noobs wiki noobs wiki noobs wiki noobs wiki noobs wiki noobs wiki noobs wiki noobs wiki noobs wiki noobs wiki noobs wiki noobs wiki noobs wiki noobs wiki noobs wiki noobs wiki noobs wiki noobs...   \n",
       "155912  aid aid aid aid aid aid aidsaids aid aid aid aid aid aidsaids aid aid aid aid aid aidsaids aid aid aid aid aid aidsaids aid aid aid aid aid aidsaids aid aid aid aid aid aidsaids aid aid aid aid aid aidsaids aid aid aid aid aid aidsaids aid aid aid aid aid aidsaids aid aid aid aid aid aidsaids ai...   \n",
       "72136   china smell like fart china smell like fart china smell like fart china smell like fart china smell like fart china smell like fart china smell like fart china smell like fart china smell like fart china smell like fart china smell like fart china smell like fart china smell like fart china smel...   \n",
       "2413    fuck u useless bot fuck u useless bot fuck u useless bot fuck u useless bot fuck u useless bot fuck u useless bot fuck u useless bot fuck u useless bot fuck u useless bot fuck u useless bot fuck u useless bot fuck u useless bot fuck u useless bot fuck u useless bot fuck u useless bot fuck u usel...   \n",
       "8697    ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball ball b...   \n",
       "47667   block block block block block block block block block block block block block block block block block block block block block block block block block block block block block block block block block block block block block block block block block block block block block block block block block bl...   \n",
       "18168   hey guy love chicken rice hey guy love chicken rice hey guy love chicken rice hey guy love chicken rice hey guy love chicken rice hey guy love chicken rice hey guy love chicken rice hey guy love chicken rice hey guy love chicken rice hey guy love chicken rice hey guy love chicken rice hey guy lo...   \n",
       "156317  huge faggot huge faggot huge faggot huge faggot huge faggot huge faggot huge faggot huge faggot huge faggot huge faggot huge faggot huge faggot huge faggot huge faggot huge faggot huge faggot huge faggot huge faggot huge faggot huge faggot huge faggot huge faggot huge faggot huge faggot huge fag...   \n",
       "153790  btw mark arsten son bitch cock place girl mouth hey guy love chicken rice hey guy love chicken rice hey guy love chicken rice hey guy love chicken rice hey guy love chicken rice hey guy love chicken rice hey guy love chicken rice hey guy love chicken rice hey guy love chicken rice hey guy love c...   \n",
       "104904  mama boy mama boy mama boy mama boymamas boy mama boymamas boy mama boymamas boy mama boymamas boy mama boymamas boy mama boymamas boy mama boymamas boy mama boymamas boy mama boymamas boy mama boymamas boy mama boymamas boy mama boymamas boy mama boymamas boy mama boymamas boy mama boymamas boy...   \n",
       "76128   nice work remove edits faggot as piece shit nice work remove edits faggot as piece shit nice work remove edits faggot as piece shit nice work remove edits faggot as piece shit nice work remove edits faggot as piece shit nice work remove edits faggot as piece shit nice work remove edits faggot as...   \n",
       "46150   heil hitler heil hitler heil hitler heil hitler heil hitler heil hitler heil hitler heil hitler heil hitler heil hitler heil hitler heil hitler heil hitler heil hitler heil hitler heil hitler heil hitler heil hitler heil hitler heil hitler heil hitler heil hitler heil hitler heil hitler heil hit...   \n",
       "131633  fffff uuuuuu cccccc kkkkkk f uu c kk fffff uuuuuu cccccc kkkkkk f uu c kk fffff uuuuuu cccccc kkkkkk f uu c kk fffff uuuuuu cccccc kkkkkk f uu c kk fffff uuuuuu cccccc kkkkkk f uu c kk fffff uuuuuu cccccc kkkkkk f uu c kk fffff uuuuuu cccccc kkkkkk f uu c kk fffff uuuuuu cccccc kkkkkk f uu c kk ...   \n",
       "17319   hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi mo...   \n",
       "\n",
       "         len  \n",
       "32114   1250  \n",
       "76542   1250  \n",
       "149925  1250  \n",
       "61746   1250  \n",
       "153236  1247  \n",
       "32371   1235  \n",
       "106871  1078  \n",
       "6564    1001  \n",
       "101685  1000  \n",
       "38030   1000  \n",
       "87388   1000  \n",
       "13041   1000  \n",
       "11946   1000  \n",
       "27124    937  \n",
       "69794    935  \n",
       "55111    915  \n",
       "93879    910  \n",
       "155912   883  \n",
       "72136    870  \n",
       "2413     869  \n",
       "8697     834  \n",
       "47667    834  \n",
       "18168    834  \n",
       "156317   834  \n",
       "153790   829  \n",
       "104904   793  \n",
       "76128    785  \n",
       "46150    770  \n",
       "131633   770  \n",
       "17319    765  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sort_values(by='len', ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Множество повторов внутри лемматизированных текстов. Оставим только уникальные значения в порядке следования в оригинальном твите"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_text</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32114</th>\n",
       "      <td>PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG ...</td>\n",
       "      <td>1</td>\n",
       "      <td>pig</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76542</th>\n",
       "      <td>DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG ...</td>\n",
       "      <td>1</td>\n",
       "      <td>die fag</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149925</th>\n",
       "      <td>LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL ...</td>\n",
       "      <td>0</td>\n",
       "      <td>lol</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61746</th>\n",
       "      <td>OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES ...</td>\n",
       "      <td>0</td>\n",
       "      <td>oh no</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153236</th>\n",
       "      <td>FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW ...</td>\n",
       "      <td>1</td>\n",
       "      <td>fat jew jewfat</td>\n",
       "      <td>1247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32371</th>\n",
       "      <td>THAT WAS REALLY MILLESECONDS WASNT IT BITCH \\n\\nFAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW ...</td>\n",
       "      <td>1</td>\n",
       "      <td>really milleseconds wasnt bitch fat jew jewfat</td>\n",
       "      <td>1235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106871</th>\n",
       "      <td>hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron...</td>\n",
       "      <td>1</td>\n",
       "      <td>hi moron moronhi</td>\n",
       "      <td>1078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6564</th>\n",
       "      <td>Sex sex sex sex Sex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex se...</td>\n",
       "      <td>1</td>\n",
       "      <td>sex sexsex</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101685</th>\n",
       "      <td>SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER ...</td>\n",
       "      <td>1</td>\n",
       "      <td>super gay</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38030</th>\n",
       "      <td>Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark B...</td>\n",
       "      <td>1</td>\n",
       "      <td>bark</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87388</th>\n",
       "      <td>SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT S...</td>\n",
       "      <td>1</td>\n",
       "      <td>shit</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13041</th>\n",
       "      <td>fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitc...</td>\n",
       "      <td>1</td>\n",
       "      <td>fuck u bitch</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11946</th>\n",
       "      <td>fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish f...</td>\n",
       "      <td>0</td>\n",
       "      <td>fish</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27124</th>\n",
       "      <td>DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU...</td>\n",
       "      <td>1</td>\n",
       "      <td>damn u cunt</td>\n",
       "      <td>937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69794</th>\n",
       "      <td>hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i li...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey like jew</td>\n",
       "      <td>935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55111</th>\n",
       "      <td>ANYONE WHO SUPPORTS THIS IS FUCKING SICK. MEN AND UNDERAGED FUCKING KIDS?????????????????????????????? WHAT IN THE FUCK YOU ALL SHOULD BE SHOT AND KILLED YOU BUNCH OF FUCKING FAGGOT PEDOPHILES\\n\\nDIE DIE DIE DIE DI EDIE DIE DIE DIE DIE\\n\\nDIE DIE DIE DIE DI EDIE DIE DIE DIE DIE\\n\\nDIE DIE DIE DI...</td>\n",
       "      <td>1</td>\n",
       "      <td>anyone support fuck sick men underaged kid shot kill bunch faggot pedophile die di edie dienew</td>\n",
       "      <td>915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93879</th>\n",
       "      <td>wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS...</td>\n",
       "      <td>1</td>\n",
       "      <td>wiki noobs n</td>\n",
       "      <td>910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155912</th>\n",
       "      <td>AIDS AIDS AIDS AIDS AIDS AIDS AIDSAIDS AIDS AIDS AIDS AIDS AIDS AIDSAIDS AIDS AIDS AIDS AIDS AIDS AIDSAIDS AIDS AIDS AIDS AIDS AIDS AIDSAIDS AIDS AIDS AIDS AIDS AIDS AIDSAIDS AIDS AIDS AIDS AIDS AIDS AIDSAIDS AIDS AIDS AIDS AIDS AIDS AIDSAIDS AIDS AIDS AIDS AIDS AIDS AIDSAIDS AIDS AIDS AIDS AIDS...</td>\n",
       "      <td>1</td>\n",
       "      <td>aid aidsaids aidsai</td>\n",
       "      <td>883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72136</th>\n",
       "      <td>China smells like fart. China smells like fart.China smells like fart.China smells like fart.China smells like fart.China smells like fart.China smells like fart.China smells like fart.China smells like fart.China smells like fart.China smells like fart.China smells like fart.China smells like f...</td>\n",
       "      <td>1</td>\n",
       "      <td>china smell like fart sm</td>\n",
       "      <td>870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2413</th>\n",
       "      <td>FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS B...</td>\n",
       "      <td>1</td>\n",
       "      <td>fuck u useless bot</td>\n",
       "      <td>869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8697</th>\n",
       "      <td>BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BA...</td>\n",
       "      <td>1</td>\n",
       "      <td>ball ba</td>\n",
       "      <td>834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47667</th>\n",
       "      <td>Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Bl...</td>\n",
       "      <td>0</td>\n",
       "      <td>block bl</td>\n",
       "      <td>834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18168</th>\n",
       "      <td>Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken ri...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey guy love chicken rice chic</td>\n",
       "      <td>834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156317</th>\n",
       "      <td>HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAG...</td>\n",
       "      <td>1</td>\n",
       "      <td>huge faggot fag</td>\n",
       "      <td>834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153790</th>\n",
       "      <td>btw mark arsten is a son of a bitch his cock is placed in a girls mouth \\nHey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I l...</td>\n",
       "      <td>1</td>\n",
       "      <td>btw mark arsten son bitch cock place girl mouth hey guy love chicken rice</td>\n",
       "      <td>829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104904</th>\n",
       "      <td>mamas boy mamas boy mamas boy mamas boymamas boy mamas boymamas boy mamas boymamas boy mamas boymamas boy mamas boymamas boy mamas boymamas boy mamas boymamas boy mamas boymamas boy mamas boymamas boy mamas boymamas boy mamas boymamas boy mamas boymamas boy mamas boymamas boy mamas boymamas boy ...</td>\n",
       "      <td>0</td>\n",
       "      <td>mama boy boymamas</td>\n",
       "      <td>793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76128</th>\n",
       "      <td>nice work removing edits, faggot ass piece of shit nice work removing edits, faggot ass piece of shit nice work removing edits, faggot ass piece of shit nice work removing edits, faggot ass piece of shit nice work removing edits, faggot ass piece of shit nice work removing edits, faggot ass piec...</td>\n",
       "      <td>1</td>\n",
       "      <td>nice work remove edits faggot as piece shit ni</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46150</th>\n",
       "      <td>heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitle...</td>\n",
       "      <td>1</td>\n",
       "      <td>heil hitler hit</td>\n",
       "      <td>770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131633</th>\n",
       "      <td>\"FFFFF UUUUUU CCCCCC KKKKKK ===== YOU! F UU C KK YOU FFFFF UUUUUU CCCCCC KKKKKK ===== YOU! F UU C KK YOU FFFFF UUUUUU CCCCCC KKKKKK ===== YOU! F UU C KK YOU FFFFF UUUUUU CCCCCC KKKKKK ===== YOU! F UU C KK YOU FFFFF UUUUUU CCCCCC KKKKKK ===== YOU! F UU C KK YOU FFFFF UUUUUU CCCCCC KKKKKK ===== YO...</td>\n",
       "      <td>1</td>\n",
       "      <td>fffff uuuuuu cccccc kkkkkk f uu c kk u</td>\n",
       "      <td>770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17319</th>\n",
       "      <td>hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi \\n\\nhi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron h...</td>\n",
       "      <td>1</td>\n",
       "      <td>hi moron</td>\n",
       "      <td>765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                               text  \\\n",
       "32114   PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG PIG ...   \n",
       "76542   DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG ...   \n",
       "149925  LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL ...   \n",
       "61746   OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES ...   \n",
       "153236  FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW ...   \n",
       "32371   THAT WAS REALLY MILLESECONDS WASNT IT BITCH \\n\\nFAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW ...   \n",
       "106871  hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron...   \n",
       "6564    Sex sex sex sex Sex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex sex sexSex sex se...   \n",
       "101685  SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER GAY SUPER ...   \n",
       "38030   Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark Bark B...   \n",
       "87388   SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT SHIT S...   \n",
       "13041   fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitches.fuck u bitc...   \n",
       "11946   fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish fish f...   \n",
       "27124   DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU...   \n",
       "69794   hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i like Jews hey i li...   \n",
       "55111   ANYONE WHO SUPPORTS THIS IS FUCKING SICK. MEN AND UNDERAGED FUCKING KIDS?????????????????????????????? WHAT IN THE FUCK YOU ALL SHOULD BE SHOT AND KILLED YOU BUNCH OF FUCKING FAGGOT PEDOPHILES\\n\\nDIE DIE DIE DIE DI EDIE DIE DIE DIE DIE\\n\\nDIE DIE DIE DIE DI EDIE DIE DIE DIE DIE\\n\\nDIE DIE DIE DI...   \n",
       "93879   wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS...   \n",
       "155912  AIDS AIDS AIDS AIDS AIDS AIDS AIDSAIDS AIDS AIDS AIDS AIDS AIDS AIDSAIDS AIDS AIDS AIDS AIDS AIDS AIDSAIDS AIDS AIDS AIDS AIDS AIDS AIDSAIDS AIDS AIDS AIDS AIDS AIDS AIDSAIDS AIDS AIDS AIDS AIDS AIDS AIDSAIDS AIDS AIDS AIDS AIDS AIDS AIDSAIDS AIDS AIDS AIDS AIDS AIDS AIDSAIDS AIDS AIDS AIDS AIDS...   \n",
       "72136   China smells like fart. China smells like fart.China smells like fart.China smells like fart.China smells like fart.China smells like fart.China smells like fart.China smells like fart.China smells like fart.China smells like fart.China smells like fart.China smells like fart.China smells like f...   \n",
       "2413    FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS B...   \n",
       "8697    BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BA...   \n",
       "47667   Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Block Bl...   \n",
       "18168   Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken ri...   \n",
       "156317  HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAGGOT HUGE FAG...   \n",
       "153790  btw mark arsten is a son of a bitch his cock is placed in a girls mouth \\nHey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I love chicken rice=)Hey guys I l...   \n",
       "104904  mamas boy mamas boy mamas boy mamas boymamas boy mamas boymamas boy mamas boymamas boy mamas boymamas boy mamas boymamas boy mamas boymamas boy mamas boymamas boy mamas boymamas boy mamas boymamas boy mamas boymamas boy mamas boymamas boy mamas boymamas boy mamas boymamas boy mamas boymamas boy ...   \n",
       "76128   nice work removing edits, faggot ass piece of shit nice work removing edits, faggot ass piece of shit nice work removing edits, faggot ass piece of shit nice work removing edits, faggot ass piece of shit nice work removing edits, faggot ass piece of shit nice work removing edits, faggot ass piec...   \n",
       "46150   heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitler! heil hitle...   \n",
       "131633  \"FFFFF UUUUUU CCCCCC KKKKKK ===== YOU! F UU C KK YOU FFFFF UUUUUU CCCCCC KKKKKK ===== YOU! F UU C KK YOU FFFFF UUUUUU CCCCCC KKKKKK ===== YOU! F UU C KK YOU FFFFF UUUUUU CCCCCC KKKKKK ===== YOU! F UU C KK YOU FFFFF UUUUUU CCCCCC KKKKKK ===== YOU! F UU C KK YOU FFFFF UUUUUU CCCCCC KKKKKK ===== YO...   \n",
       "17319   hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi \\n\\nhi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron hi moron h...   \n",
       "\n",
       "        toxic  \\\n",
       "32114       1   \n",
       "76542       1   \n",
       "149925      0   \n",
       "61746       0   \n",
       "153236      1   \n",
       "32371       1   \n",
       "106871      1   \n",
       "6564        1   \n",
       "101685      1   \n",
       "38030       1   \n",
       "87388       1   \n",
       "13041       1   \n",
       "11946       0   \n",
       "27124       1   \n",
       "69794       0   \n",
       "55111       1   \n",
       "93879       1   \n",
       "155912      1   \n",
       "72136       1   \n",
       "2413        1   \n",
       "8697        1   \n",
       "47667       0   \n",
       "18168       0   \n",
       "156317      1   \n",
       "153790      1   \n",
       "104904      0   \n",
       "76128       1   \n",
       "46150       1   \n",
       "131633      1   \n",
       "17319       1   \n",
       "\n",
       "                                                                                             lemm_text  \\\n",
       "32114                                                                                              pig   \n",
       "76542                                                                                          die fag   \n",
       "149925                                                                                             lol   \n",
       "61746                                                                                            oh no   \n",
       "153236                                                                                  fat jew jewfat   \n",
       "32371                                                   really milleseconds wasnt bitch fat jew jewfat   \n",
       "106871                                                                                hi moron moronhi   \n",
       "6564                                                                                        sex sexsex   \n",
       "101685                                                                                       super gay   \n",
       "38030                                                                                             bark   \n",
       "87388                                                                                             shit   \n",
       "13041                                                                                     fuck u bitch   \n",
       "11946                                                                                             fish   \n",
       "27124                                                                                      damn u cunt   \n",
       "69794                                                                                     hey like jew   \n",
       "55111   anyone support fuck sick men underaged kid shot kill bunch faggot pedophile die di edie dienew   \n",
       "93879                                                                                     wiki noobs n   \n",
       "155912                                                                             aid aidsaids aidsai   \n",
       "72136                                                                         china smell like fart sm   \n",
       "2413                                                                                fuck u useless bot   \n",
       "8697                                                                                           ball ba   \n",
       "47667                                                                                         block bl   \n",
       "18168                                                                   hey guy love chicken rice chic   \n",
       "156317                                                                                 huge faggot fag   \n",
       "153790                       btw mark arsten son bitch cock place girl mouth hey guy love chicken rice   \n",
       "104904                                                                               mama boy boymamas   \n",
       "76128                                                   nice work remove edits faggot as piece shit ni   \n",
       "46150                                                                                  heil hitler hit   \n",
       "131633                                                          fffff uuuuuu cccccc kkkkkk f uu c kk u   \n",
       "17319                                                                                         hi moron   \n",
       "\n",
       "         len  \n",
       "32114   1250  \n",
       "76542   1250  \n",
       "149925  1250  \n",
       "61746   1250  \n",
       "153236  1247  \n",
       "32371   1235  \n",
       "106871  1078  \n",
       "6564    1001  \n",
       "101685  1000  \n",
       "38030   1000  \n",
       "87388   1000  \n",
       "13041   1000  \n",
       "11946   1000  \n",
       "27124    937  \n",
       "69794    935  \n",
       "55111    915  \n",
       "93879    910  \n",
       "155912   883  \n",
       "72136    870  \n",
       "2413     869  \n",
       "8697     834  \n",
       "47667    834  \n",
       "18168    834  \n",
       "156317   834  \n",
       "153790   829  \n",
       "104904   793  \n",
       "76128    785  \n",
       "46150    770  \n",
       "131633   770  \n",
       "17319    765  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['lemm_text'] = data['lemm_text'].apply(lambda x: ' '.join(sorted(set(x.split()), key=x.split().index)))\n",
    "\n",
    "data.sort_values(by='len', ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим столбец с пересчитанным количеством слов после сокращения лемматизированного текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['len_lemmed'] = data['lemm_text'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 157392 entries, 0 to 157391\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   index       157392 non-null  int64 \n",
      " 1   text        157392 non-null  object\n",
      " 2   toxic       157392 non-null  int64 \n",
      " 3   lemm_text   157392 non-null  object\n",
      " 4   len         157392 non-null  int64 \n",
      " 5   len_lemmed  157392 non-null  int64 \n",
      "dtypes: int64(4), object(2)\n",
      "memory usage: 7.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Краткий вывод\n",
    "\n",
    "Данные представляют собой размеченный датасет из ~160 тыс. комментариев и отметки токсичности.\n",
    "\n",
    "Данные загружены, очищены от не-латинских символов, приведены к нижнему регистру и лемматизированы.\n",
    "\n",
    "После обработки проведена повторная проверка на дубликаты, которые были удалены из датасета.  \n",
    "По итогу осталось почти 158 тыс. строк."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных к обучению моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобьем набор данных на обучающую и тестовую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размеры выборок:\n",
      "Обучающая выборка: 125913 строк\n",
      "Тестовая выборка: 31479 строк\n",
      "Соотношение:  80.0 : 20.0\n"
     ]
    }
   ],
   "source": [
    "X = data['lemm_text'] #.values.astype('U')\n",
    "y = data['toxic']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, \n",
    "                y, \n",
    "                train_size=.8, \n",
    "                shuffle=True,\n",
    "                stratify=y, \n",
    "                random_state=RS\n",
    "            )\n",
    "\n",
    "\n",
    "print('Размеры выборок:')\n",
    "print(f'Обучающая выборка: {X_train.shape[0]} строк')\n",
    "print(f'Тестовая выборка: {X_test.shape[0]} строк')\n",
    "print(f\"Соотношение: \",\n",
    "    f\"{round(X_train.shape[0] / (X_train.shape[0] + X_test.shape[0]) * 100, 2)} :\",\n",
    "    f\"{round(X_test.shape[0] / (X_train.shape[0] + X_test.shape[0]) * 100, 2)}\")\n",
    "\n",
    "#print(f'Количество признаков: {X_train.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим качество моделей логистической регрессии, случайного леса и LGBM.\n",
    "\n",
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    ('tfidf', TfidfVectorizer(stop_words=list(stops))),\n",
    "    ('model', LogisticRegression(class_weight='balanced', random_state=RS))\n",
    "])\n",
    "\n",
    "\n",
    "LR_parameters = {'tfidf__min_df': [1, 3, 10],\n",
    "                 'tfidf__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
    "                 'model__C': [1, 5, 10],\n",
    "                 'model__solver': [\"liblinear\", \"saga\"],\n",
    "\n",
    "                }\n",
    "\n",
    "LR_grid = GridSearchCV(\n",
    "    pipe, \n",
    "    param_grid=LR_parameters,\n",
    "    scoring='f1',\n",
    "    cv=5,\n",
    "    error_score='raise'\n",
    ")\n",
    "\n",
    "LR_grid.fit(X_train, y_train)\n",
    "\n",
    "best_f1_LR = LR_grid.best_score_\n",
    "best_params_LR = LR_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.7782424165477312\n",
      "Parameters: {'model__C': 10, 'model__solver': 'saga', 'tfidf__min_df': 1, 'tfidf__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "print('F1:', best_f1_LR) \n",
    "print('Parameters:', best_params_LR)\n",
    "\n",
    "best_LR_model = LR_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лес страшно запускать - итак три часа учился, с добавлением tf-idf вообще умрет от старости, думаю :(  \n",
    "Да и метрика все равно унылая, сомнительно, что поднимет ее в полтора раза"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Temp\\Ya_Pr\\YaPr_m4_s26_review2.ipynb Cell 78\u001b[0m line \u001b[0;36m<cell line: 22>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Temp/Ya_Pr/YaPr_m4_s26_review2.ipynb#Y140sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m RF_parameters \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mtfidf__min_df\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m10\u001b[39m],\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Temp/Ya_Pr/YaPr_m4_s26_review2.ipynb#Y140sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m                  \u001b[39m'\u001b[39m\u001b[39mtfidf__ngram_range\u001b[39m\u001b[39m'\u001b[39m: [(\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m), (\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m), (\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m)],\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Temp/Ya_Pr/YaPr_m4_s26_review2.ipynb#Y140sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m                  \u001b[39m'\u001b[39m\u001b[39mmodel__max_depth\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m40\u001b[39m, \u001b[39m60\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Temp/Ya_Pr/YaPr_m4_s26_review2.ipynb#Y140sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                  \u001b[39m'\u001b[39m\u001b[39mmodel__n_estimators\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m600\u001b[39m, \u001b[39m1000\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Temp/Ya_Pr/YaPr_m4_s26_review2.ipynb#Y140sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Temp/Ya_Pr/YaPr_m4_s26_review2.ipynb#Y140sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m                 }\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Temp/Ya_Pr/YaPr_m4_s26_review2.ipynb#Y140sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m RF_grid \u001b[39m=\u001b[39m GridSearchCV(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Temp/Ya_Pr/YaPr_m4_s26_review2.ipynb#Y140sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     pipe, \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Temp/Ya_Pr/YaPr_m4_s26_review2.ipynb#Y140sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     param_grid\u001b[39m=\u001b[39mRF_parameters,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Temp/Ya_Pr/YaPr_m4_s26_review2.ipynb#Y140sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     error_score\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Temp/Ya_Pr/YaPr_m4_s26_review2.ipynb#Y140sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Temp/Ya_Pr/YaPr_m4_s26_review2.ipynb#Y140sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m RF_grid\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Temp/Ya_Pr/YaPr_m4_s26_review2.ipynb#Y140sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m best_f1_RF \u001b[39m=\u001b[39m RF_grid\u001b[39m.\u001b[39mbest_score_\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Temp/Ya_Pr/YaPr_m4_s26_review2.ipynb#Y140sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m best_params_RF \u001b[39m=\u001b[39m RF_grid\u001b[39m.\u001b[39mbest_params_\n",
      "File \u001b[1;32mc:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\pipeline.py:401\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit the model.\u001b[39;00m\n\u001b[0;32m    376\u001b[0m \n\u001b[0;32m    377\u001b[0m \u001b[39mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[39m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    400\u001b[0m fit_params_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_fit_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m--> 401\u001b[0m Xt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_steps)\n\u001b[0;32m    402\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)):\n\u001b[0;32m    403\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\pipeline.py:359\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    357\u001b[0m     cloned_transformer \u001b[39m=\u001b[39m clone(transformer)\n\u001b[0;32m    358\u001b[0m \u001b[39m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[1;32m--> 359\u001b[0m X, fitted_transformer \u001b[39m=\u001b[39m fit_transform_one_cached(\n\u001b[0;32m    360\u001b[0m     cloned_transformer,\n\u001b[0;32m    361\u001b[0m     X,\n\u001b[0;32m    362\u001b[0m     y,\n\u001b[0;32m    363\u001b[0m     \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    364\u001b[0m     message_clsname\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    365\u001b[0m     message\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(step_idx),\n\u001b[0;32m    366\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_steps[name],\n\u001b[0;32m    367\u001b[0m )\n\u001b[0;32m    368\u001b[0m \u001b[39m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[0;32m    369\u001b[0m \u001b[39m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[39m# from the cache.\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[step_idx] \u001b[39m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[1;32mc:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\joblib\\memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 349\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\pipeline.py:893\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    891\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m    892\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformer, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 893\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit_transform(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    894\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    895\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:2131\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   2124\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_params()\n\u001b[0;32m   2125\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tfidf \u001b[39m=\u001b[39m TfidfTransformer(\n\u001b[0;32m   2126\u001b[0m     norm\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm,\n\u001b[0;32m   2127\u001b[0m     use_idf\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_idf,\n\u001b[0;32m   2128\u001b[0m     smooth_idf\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msmooth_idf,\n\u001b[0;32m   2129\u001b[0m     sublinear_tf\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msublinear_tf,\n\u001b[0;32m   2130\u001b[0m )\n\u001b[1;32m-> 2131\u001b[0m X \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit_transform(raw_documents)\n\u001b[0;32m   2132\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tfidf\u001b[39m.\u001b[39mfit(X)\n\u001b[0;32m   2133\u001b[0m \u001b[39m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[0;32m   2134\u001b[0m \u001b[39m# we set copy to False\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1387\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1379\u001b[0m             warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1380\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mUpper case characters found in\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1381\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m vocabulary while \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlowercase\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1382\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m is True. These entries will not\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1383\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m be matched with any documents\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1384\u001b[0m             )\n\u001b[0;32m   1385\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m-> 1387\u001b[0m vocabulary, X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_count_vocab(raw_documents, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfixed_vocabulary_)\n\u001b[0;32m   1389\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbinary:\n\u001b[0;32m   1390\u001b[0m     X\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mfill(\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1278\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1276\u001b[0m feature_idx \u001b[39m=\u001b[39m vocabulary[feature]\n\u001b[0;32m   1277\u001b[0m \u001b[39mif\u001b[39;00m feature_idx \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m feature_counter:\n\u001b[1;32m-> 1278\u001b[0m     feature_counter[feature_idx] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1279\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1280\u001b[0m     feature_counter[feature_idx] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    ('tfidf', TfidfVectorizer(stop_words=list(stops))),\n",
    "    ('model', RandomForestClassifier(class_weight='balanced', random_state=RS))\n",
    "])\n",
    "\n",
    "\n",
    "RF_parameters = {'tfidf__min_df': [1, 3, 10],\n",
    "                 'tfidf__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
    "                 'model__max_depth': [40, 60],\n",
    "                 'model__n_estimators': [600, 1000],\n",
    "\n",
    "                }\n",
    "\n",
    "RF_grid = GridSearchCV(\n",
    "    pipe, \n",
    "    param_grid=RF_parameters,\n",
    "    scoring='f1',\n",
    "    cv=5,\n",
    "    error_score='raise'\n",
    ")\n",
    "\n",
    "RF_grid.fit(X_train, y_train)\n",
    "\n",
    "best_f1_RF = RF_grid.best_score_\n",
    "best_params_RF = RF_grid.best_params_\n",
    "\n",
    "best_RF_model = RF_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('F1:',best_f1_RF) \n",
    "# print('Parameters:', best_params_RF)\n",
    "\n",
    "best_f1_RF = 0\n",
    "best_params_RF = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хотелось бы подобрать гиперпараметры с помощью Optuna, но учится крайне долго (\n",
    "\n",
    "Вместо леса потестируем Passive Aggressive Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    ('tfidf', TfidfVectorizer(stop_words=list(stops))),\n",
    "    ('model', PassiveAggressiveClassifier(class_weight='balanced', random_state=RS, n_jobs=-1))\n",
    "])\n",
    "\n",
    "\n",
    "PAC_parameters = {'tfidf__min_df': [1, 3, 10],\n",
    "                 'tfidf__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
    "                 'model__max_iter': [50, 100],\n",
    "                 'model__C': [1, 5, 10],\n",
    "\n",
    "                }\n",
    "\n",
    "PAC_grid = GridSearchCV(\n",
    "    pipe, \n",
    "    param_grid=PAC_parameters,\n",
    "    scoring='f1',\n",
    "    cv=5,\n",
    "    error_score='raise'\n",
    ")\n",
    "\n",
    "PAC_grid.fit(X_train, y_train)\n",
    "\n",
    "best_f1_PAC = PAC_grid.best_score_\n",
    "best_params_PAC = PAC_grid.best_params_\n",
    "\n",
    "best_PAC_model = PAC_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.773928520617828\n",
      "Parameters: {'model__C': 1, 'model__max_iter': 50, 'tfidf__min_df': 1, 'tfidf__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "print('F1:', best_f1_PAC) \n",
    "print('Parameters:', best_params_PAC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBMClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогично остальным моделям, гиперпараметры с помощью Optuna подбирать оч долго :(("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.901799 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 466982\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8667\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.876770 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 467395\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8725\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.752321 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 466703\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8678\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.825360 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 467781\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 8679\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.795215 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 465936\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 8663\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.503937 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 624110\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 16961\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.520786 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 624475\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 17037\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.542299 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 623388\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 16978\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.488808 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 624557\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 16958\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.512788 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 622775\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 16950\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.665254 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 154087\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8294\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.670656 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 153974\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8312\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.713328 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 153775\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8300\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.720067 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 153646\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 8279\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.700033 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 153522\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 8287\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.781069 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 466868\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8667\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.785111 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 467300\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8725\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.809412 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 466588\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8678\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.839557 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 467648\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 8679\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.806684 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 465795\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 8663\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.456733 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 623461\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 16961\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.495334 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 624073\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 17037\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.499252 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 622811\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 16978\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.532626 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 623825\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 16958\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.471962 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 621943\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 16950\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.790941 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 148214\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8294\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.862185 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 148163\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8312\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.922492 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 147888\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8300\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.793375 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 147753\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 8279\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.777003 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 147490\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 8287\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.874382 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 466737\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8667\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.794787 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 467168\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8725\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.837508 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 466465\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8678\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.773238 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 467565\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 8679\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.767417 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 465689\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 8663\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.569128 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 622514\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 16961\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.552451 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 623036\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 17037\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.607710 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 621913\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 16978\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.465404 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 622791\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 16958\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.520796 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620898\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 16950\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.708679 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 143340\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8294\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.698703 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 143554\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8312\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.696532 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 143091\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8300\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.735376 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 142662\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 8279\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.718686 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 142681\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 8287\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.801883 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 466982\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8667\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.805095 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 467395\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8725\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.810517 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 466703\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8678\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.883273 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 467781\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 8679\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.740904 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 465936\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 8663\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.537844 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 624110\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 16961\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.668192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 624475\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 17037\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.573497 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 623388\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 16978\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.494060 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 624557\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 16958\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.453658 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 622775\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 16950\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.661374 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 154087\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8294\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.635223 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 153974\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8312\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.659661 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 153775\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8300\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.649464 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 153646\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 8279\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.634754 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 153522\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 8287\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.778451 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 466868\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8667\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.812946 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 467300\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8725\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.910863 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 466588\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8678\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.800211 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 467648\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 8679\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.848283 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 465795\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 8663\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.712616 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 623461\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 16961\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.750793 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 624073\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 17037\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.616348 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 622811\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 16978\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.691030 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 623825\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 16958\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.603673 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 621943\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 16950\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.740442 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 148214\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8294\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.737643 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 148163\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8312\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.701636 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 147888\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8300\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.701448 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 147753\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 8279\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.687783 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 147490\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 8287\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.834942 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 466737\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8667\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.925427 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 467168\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8725\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.789504 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 466465\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8678\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.815498 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 467565\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 8679\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.817219 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 465689\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 8663\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.497254 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 622514\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 16961\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.585532 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 623036\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 17037\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.484958 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 621913\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 16978\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.579525 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 622791\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 16958\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.481323 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 620898\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 16950\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.698026 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 143340\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8294\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.725082 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 143554\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8312\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.771750 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 143091\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8300\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.676645 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 142662\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 8279\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.653605 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 142681\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 8287\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.764340 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 466982\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8667\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.771974 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 467395\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8725\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.786414 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 466703\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8678\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.777402 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 467781\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 8679\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.835766 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 465936\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 8663\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.550244 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 624110\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 16961\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.508285 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 624475\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 17037\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.551857 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 623388\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 16978\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.502564 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 624557\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 16958\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.480337 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 622775\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 16950\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.663314 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 154087\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8294\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.704271 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 153974\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8312\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.670523 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 153775\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8300\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.714815 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 153646\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 8279\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.667741 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 153522\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 8287\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.771033 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 466868\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8667\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.850016 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 467300\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8725\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.774311 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 466588\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8678\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.783808 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 467648\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 8679\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.787995 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 465795\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 8663\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.485606 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 623461\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 16961\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.468953 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 624073\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 17037\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.476209 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 622811\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 16978\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.520502 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 623825\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 16958\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.505095 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 621943\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 16950\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.680663 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 148214\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8294\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.688651 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 148163\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8312\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.672920 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 147888\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8300\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.666658 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 147753\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 8279\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.710320 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 147490\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 8287\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.767710 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 466737\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8667\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.802484 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 467168\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8725\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.773327 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 466465\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8678\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.789447 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 467565\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 8679\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.768884 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 465689\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 8663\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.470869 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 622514\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 16961\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.453657 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 623036\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 17037\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.518760 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 621913\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 16978\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.461730 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 622791\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 16958\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.410273 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 620898\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 16950\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.678930 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 143340\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8294\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.636301 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 143554\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8312\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.656789 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 143091\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8300\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.650748 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 142662\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 8279\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.645748 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 142681\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 8287\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.734998 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 466982\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8667\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.756254 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 467395\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8725\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.770061 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 466703\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8678\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.793962 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 467781\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 8679\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.775850 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 465936\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 8663\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.526734 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 624110\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 16961\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.491630 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 624475\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 17037\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.497351 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 623388\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 16978\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.493479 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 624557\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 16958\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.515910 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 622775\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 16950\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.690033 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 154087\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8294\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.689102 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 153974\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8312\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.700519 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 153775\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8300\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.689246 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 153646\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 8279\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.721164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 153522\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 8287\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.772021 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 466868\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8667\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.805955 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 467300\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8725\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.775503 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 466588\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8678\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.767650 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 467648\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 8679\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.781251 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 465795\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 8663\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.483806 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 623461\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 16961\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.502588 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 624073\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 17037\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.763282 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 622811\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 16978\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.496779 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 623825\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 16958\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.503714 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 621943\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 16950\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.694360 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 148214\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8294\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.703764 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 148163\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8312\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.700698 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 147888\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8300\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.683548 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 147753\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 8279\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.701193 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 147490\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 8287\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.749571 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 466737\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8667\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.753342 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 467168\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8725\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.756320 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 466465\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8678\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.772752 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 467565\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 8679\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.780832 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 465689\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 8663\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.478306 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 622514\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 16961\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.528487 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 623036\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 17037\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.490710 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 621913\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 16978\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.552441 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 622791\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 16958\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.523214 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 620898\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 16950\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.764096 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 143340\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8294\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.707343 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 143554\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8312\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.642454 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 143091\n",
      "[LightGBM] [Info] Number of data points in the train set: 100730, number of used features: 8300\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.711159 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 142662\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 8279\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10231, number of negative: 90500\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.671055 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 142681\n",
      "[LightGBM] [Info] Number of data points in the train set: 100731, number of used features: 8287\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 12788, number of negative: 113125\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 2.283259 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762031\n",
      "[LightGBM] [Info] Number of data points in the train set: 125913, number of used features: 20921\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    ('tfidf', TfidfVectorizer(stop_words=list(stops))),\n",
    "    ('model', LGBMClassifier(learning_rate=0.1, class_weight='balanced', random_state=RS, n_jobs=-1))\n",
    "])\n",
    "\n",
    "\n",
    "LGBM_parameters = {'tfidf__min_df': [1, 3, 10],\n",
    "                 'tfidf__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
    "                 'model__max_depth': [50, 100],\n",
    "                 'model__n_estimators': [600, 1000]\n",
    "\n",
    "                }\n",
    "\n",
    "LGBM_grid = GridSearchCV(\n",
    "    pipe, \n",
    "    param_grid=LGBM_parameters,\n",
    "    scoring='f1',\n",
    "    cv=5,\n",
    "    error_score='raise'\n",
    ")\n",
    "\n",
    "LGBM_grid.fit(X_train, y_train)\n",
    "\n",
    "best_f1_LGBM = LGBM_grid.best_score_\n",
    "best_params_LGBM = LGBM_grid.best_params_\n",
    "\n",
    "best_LGBM_model = LGBM_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.7645027202071883\n",
      "Parameters: {'model__max_depth': 50, 'model__n_estimators': 1000, 'tfidf__min_df': 1, 'tfidf__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "print('F1:', best_f1_LGBM) \n",
    "print('Parameters:', best_params_LGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogisticRegresion</th>\n",
       "      <th>PassiveAgressive</th>\n",
       "      <th>LGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-score</th>\n",
       "      <td>0.778242</td>\n",
       "      <td>0.773929</td>\n",
       "      <td>0.764503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          LogisticRegresion  PassiveAgressive      LGBM\n",
       "F1-score           0.778242          0.773929  0.764503"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame([[best_f1_LR, best_f1_PAC, best_f1_LGBM]],\n",
    "                       index=['F1-score'], \n",
    "                       columns=['LogisticRegresion', 'PassiveAgressive', 'LGBM']\n",
    "                       )\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Краткий вывод\n",
    "\n",
    "Данные разбиты на обучающую и тестовую выборки.\n",
    "\n",
    "Обучены модели классификации логистической регрессии, случайного леса LGBM.  \n",
    "Оценка моделей проводилась по метрике F1-score.\n",
    "\n",
    "С небольшим перевесом максимальный показатель метрики выдала модель логистической регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка лучшей модели на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 on test (logisticRegression): 0.782727687395469\n",
      "F1 on test (PassiveAgressiveClassifier): 0.7815219110900175\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "F1 on test (LightGBMClassifier): 0.7725242568920377\n"
     ]
    }
   ],
   "source": [
    "print('F1 on test (logisticRegression):', f1_score(y_test, best_LR_model.predict(X_test)))\n",
    "\n",
    "print('F1 on test (PassiveAgressiveClassifier):', f1_score(y_test, best_PAC_model.predict(X_test)))\n",
    "\n",
    "print('F1 on test (LightGBMClassifier):', f1_score(y_test, best_LGBM_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку все модели дали приблизительно равный результат, прогнал на тесте их все.  \n",
    "\n",
    "Победа все равно за Логистической регрессией!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>645564</th>\n",
       "      <td>fuck</td>\n",
       "      <td>54.876074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470729</th>\n",
       "      <td>shit</td>\n",
       "      <td>33.297263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769922</th>\n",
       "      <td>idiot</td>\n",
       "      <td>32.948098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1568604</th>\n",
       "      <td>stupid</td>\n",
       "      <td>31.235657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576148</th>\n",
       "      <td>suck</td>\n",
       "      <td>27.138583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124514</th>\n",
       "      <td>asshole</td>\n",
       "      <td>25.466890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223408</th>\n",
       "      <td>bullshit</td>\n",
       "      <td>24.349471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189248</th>\n",
       "      <td>bitch</td>\n",
       "      <td>24.329278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040362</th>\n",
       "      <td>moron</td>\n",
       "      <td>22.490647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374077</th>\n",
       "      <td>crap</td>\n",
       "      <td>22.484031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440741</th>\n",
       "      <td>dick</td>\n",
       "      <td>22.427722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581092</th>\n",
       "      <td>faggot</td>\n",
       "      <td>21.158652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387337</th>\n",
       "      <td>cunt</td>\n",
       "      <td>20.930494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179402</th>\n",
       "      <td>pathetic</td>\n",
       "      <td>18.464069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161733</th>\n",
       "      <td>bastard</td>\n",
       "      <td>18.049866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658442</th>\n",
       "      <td>gay</td>\n",
       "      <td>17.544071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482817</th>\n",
       "      <td>dumb</td>\n",
       "      <td>17.373077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847720</th>\n",
       "      <td>jerk</td>\n",
       "      <td>17.334926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185130</th>\n",
       "      <td>penis</td>\n",
       "      <td>16.979613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087546</th>\n",
       "      <td>nigger</td>\n",
       "      <td>16.799534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Feature       Coef\n",
       "645564       fuck  54.876074\n",
       "1470729      shit  33.297263\n",
       "769922      idiot  32.948098\n",
       "1568604    stupid  31.235657\n",
       "1576148      suck  27.138583\n",
       "124514    asshole  25.466890\n",
       "223408   bullshit  24.349471\n",
       "189248      bitch  24.329278\n",
       "1040362     moron  22.490647\n",
       "374077       crap  22.484031\n",
       "440741       dick  22.427722\n",
       "581092     faggot  21.158652\n",
       "387337       cunt  20.930494\n",
       "1179402  pathetic  18.464069\n",
       "161733    bastard  18.049866\n",
       "658442        gay  17.544071\n",
       "482817       dumb  17.373077\n",
       "847720       jerk  17.334926\n",
       "1185130     penis  16.979613\n",
       "1087546    nigger  16.799534"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = best_LR_model[0].get_feature_names_out().tolist()\n",
    "coefs = best_LR_model[1].coef_.tolist()[0]\n",
    "\n",
    "weights = pd.DataFrame(list(zip(features, coefs)), columns=['Feature', 'Coef']).sort_values(by='Coef',ascending=False).head(20)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x=weights['Feature'], y=weights['Coef'])\n",
    "\n",
    "plt.xlabel('Слово в твите как признак')\n",
    "plt.ylabel('Важность (коэффициент)')\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "\n",
    "plt.title('Важность признаков');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметим, что Википедия пропала из списка важных для модели слов :)  \n",
    "В остальном - график говорит сам за себя."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем использовать нейронную сеть BERT.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заново загрузим данные, так как лемматизация и очистка текста проходят внутри Берты\n",
    "pth1 = 'D:\\Temp\\Ya_Pr\\toxic_comments.csv'\n",
    "\n",
    "if os.path.exists(pth1):\n",
    "    data = pd.read_csv(pth1, index_col=[0])\n",
    "elif not os.path.exists(pth1):\n",
    "    data = pd.read_csv('https://code.s3.yandex.net//datasets//toxic_comments.csv', index_col=[0])\n",
    "else:\n",
    "    print('Something is wrong')\n",
    "\n",
    "\n",
    "# Возьмем 5000 строк, дабы не ждать слишком долго\n",
    "data_small = data.sample(5000, random_state=RS).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3949, 2)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_small = data_small[data_small['text'].str.len() < 512]\n",
    "\n",
    "data_small.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отрежем еще чуть-чуть, чтобы было кратно размеру батча\n",
    "data_small = data_small[:3900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at unitary/toxic-bert were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "config = transformers.BertConfig.from_pretrained('unitary/toxic-bert')\n",
    "model = transformers.BertModel.from_pretrained('unitary/toxic-bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained('unitary/toxic-bert')\n",
    "\n",
    "tokenized = data_small['text'].apply(\n",
    "    lambda x: tokenizer.encode(x, add_special_tokens=True)\n",
    ")\n",
    "\n",
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "\n",
    "attention_mask = np.where(padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3900, 192)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f47f7a755984495bcc0bb66cb914ee0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 300\n",
    "\n",
    "# Кстати, размер батча ограничивается исключительно мощнотями доступными? \n",
    "\n",
    "embeddings = []\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "        batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.concatenate(embeddings)\n",
    "target = data_small['toxic']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                features, \n",
    "                target, \n",
    "                train_size=.8, \n",
    "                shuffle=True,\n",
    "                stratify=target, \n",
    "                random_state=RS\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\apple\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "LR_bert_arameters = {'C': [1, 5, 10],\n",
    "                 'solver': [\"liblinear\", \"saga\"],\n",
    "                 'penalty': ['l1', 'l2']\n",
    "\n",
    "                }\n",
    "\n",
    "LR_bert = LogisticRegression(random_state=RS)\n",
    "\n",
    "\n",
    "LR_bert_grid = GridSearchCV(\n",
    "    LR_bert, \n",
    "    param_grid=LR_bert_arameters,\n",
    "    scoring='f1',\n",
    "    cv=5,\n",
    "    error_score='raise'\n",
    ")\n",
    "\n",
    "LR_bert_grid.fit(X_train, y_train)\n",
    "\n",
    "best_f1_LR_bert = LR_bert_grid.best_score_\n",
    "best_params_LR_bert = LR_bert_grid.best_params_\n",
    "\n",
    "best_LR_bert = LR_bert_grid.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogisticRegresion</th>\n",
       "      <th>PassiveAgressive</th>\n",
       "      <th>LGBM</th>\n",
       "      <th>Bert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-score</th>\n",
       "      <td>0.778242</td>\n",
       "      <td>0.773929</td>\n",
       "      <td>0.764503</td>\n",
       "      <td>0.956827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          LogisticRegresion  PassiveAgressive      LGBM      Bert\n",
       "F1-score           0.778242          0.773929  0.764503  0.956827"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['Bert'] = best_f1_LR_bert\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 (BERT): 0.9206349206349206\n"
     ]
    }
   ],
   "source": [
    "preds = best_LR_bert.predict(X_test)\n",
    "\n",
    "print('F1 (BERT):', f1_score(y_test, preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Краткий вывод\n",
    "\n",
    "BERT показала себя заметно лучше классических моделей (F1-score = 0.92).\n",
    "\n",
    "P.S. Он реально настолько круче!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По исходным данным (датасет из ~160 тыс. комментариев и отметки токсичности) необходимо разработать модель оценки токсичности комментария.  \n",
    "Необходимо достичь показателя метрики F1-score не менее 0,75.\n",
    "\n",
    "Для решения задачи данные загружены, очищены от не-латинских символов, приведены к нижнему регистру и лемматизированы.\n",
    "\n",
    "Проведена проверка на дубликаты, которые были удалены из датасета.  \n",
    "По итогу осталось почти 158 тыс. строк.\n",
    "\n",
    "Данные разбиты на обучающую и тестовую выборки в оотношении 5:1; подготовлен пайплайн для обучения моделей с помощью tf-idf-векторизации.\n",
    "\n",
    "Обучены модели классификации логистической регрессии, случайного леса LGBM.  \n",
    "Оценка моделей проводилась по метрике F1-score.\n",
    "\n",
    "С небольшим перевесом максимальный показатель метрики выдала модель логистической регрессии.\n",
    "\n",
    "Лучшая модель проверена на тестовой выборке. Показатель целевой метрики составил 0,778, что удовлетворяет поставленной задаче.\n",
    "\n",
    "---\n",
    "\n",
    "Также проведен эксперимент с использованием нейронной сети BERT для поиска токсичных комментариев.  \n",
    "Она показала заметно лучший результат (0,92)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
